{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25VtmxUB6Iz8",
        "outputId": "04423d0a-8bd6-4b99-8d63-ddbc74cac8b2"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 62 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 41.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=c7d6dd66c0e6c12679ce3d1d65414d4ca9d9361b898828a60333e1c9120541e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF_Sm0Ny53mA",
        "outputId": "ec0c5b3c-8060-402d-a80d-5ef9a8487c23"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "from operator import add\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "import string\n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "from pyspark.sql.window import Window\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "conf = SparkConf().setMaster(\"local\").setAppName(\"My App\")\n",
        "sc = SparkContext(conf = conf)\n",
        "spark = SparkSession(sc)\n",
        "\n",
        "stop_words = list(STOPWORDS)\n",
        "stop_words.extend(list(''+' '+string.punctuation + string.digits))\n",
        "\n",
        "with open(\"/content/nytimes_news_articles.txt\", \"r\") as f:  # 打开文件\n",
        "    data = f.read()  # 读取文件\n",
        "data = data.split('\\n\\n')\n",
        "key = []\n",
        "for i in range(len(data)):\n",
        "    if 'URL: http://www.nytimes.com/' in data[i]:\n",
        "        tem = '/'.join(data[i][39:].split('/')[:-1])\n",
        "        continue\n",
        "    temp = data[i].lower()\n",
        "    key.append((tem, temp.split(' ')))\n",
        "\n",
        "pairRDD = sc.parallelize(key).toDF(['class','message'])\n",
        "remover = StopWordsRemover(stopWords=stop_words,inputCol='message', outputCol='message_clean')\n",
        "pairRDD = remover.transform(pairRDD).select('class', 'message_clean')\n",
        "count_RDD=pairRDD.withColumn(\"word\",F.explode(\"message_clean\")).groupBy(\"class\",\"word\").count()\n",
        "windows_spec = Window.partitionBy(\"class\").orderBy(F.col(\"count\").desc())\n",
        "most_words = count_RDD.withColumn(\"rank\", F.rank().over(windows_spec)).filter(\"rank <=10\")\n",
        "most_words.show()\n",
        "\n",
        "most_words.toPandas().to_csv('/content/task3_ans.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+---------+-----+----+\n",
            "|              class|     word|count|rank|\n",
            "+-------------------+---------+-----+----+\n",
            "|             travel|        —|  610|   1|\n",
            "|             travel|     like|  352|   2|\n",
            "|             travel|      new|  313|   3|\n",
            "|             travel|     said|  218|   4|\n",
            "|             travel|     it’s|  206|   5|\n",
            "|             travel|    hotel|  202|   6|\n",
            "|             travel|   travel|  187|   7|\n",
            "|             travel|   people|  155|   8|\n",
            "|             travel|      mr.|  150|   9|\n",
            "|             travel|including|  149|  10|\n",
            "|             travel|     city|  149|  10|\n",
            "|sports/horse-racing|    derby|  146|   1|\n",
            "|sports/horse-racing|    horse|  122|   2|\n",
            "|sports/horse-racing|        —|   90|   3|\n",
            "|sports/horse-racing| kentucky|   88|   4|\n",
            "|sports/horse-racing|     said|   85|   5|\n",
            "|sports/horse-racing|     colt|   84|   6|\n",
            "|sports/horse-racing|   horses|   81|   7|\n",
            "|sports/horse-racing|  nyquist|   76|   8|\n",
            "|sports/horse-racing|    said.|   72|   9|\n",
            "+-------------------+---------+-----+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}